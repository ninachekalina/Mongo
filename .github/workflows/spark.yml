name: Spark CI

on:
  push:
    branches:
      - 'master'
  pull_request:
    branches:
      - 'main'
  workflow_dispatch:
    inputs:
      query_key:
        description: 'key to extract query from artifact'
        required: false

jobs:
  spark-submit:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        python:
          - '3.10'
          - '3.11'
        spark:
          - '3.3.2'
          - '3.4.0'
          - '3.5.3'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'

      - name: Setup Spark
        uses: vemonet/setup-spark@v1
        with:
          spark-version: ${{ matrix.spark }}
          hadoop-version: '3'

      - name: Check Spark version
        run: spark-submit --version

      - name: Download dataset from Kaggle
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        run: |
          mkdir -p data
          kaggle datasets download -d chekalinanina/netflix-titles -p data --unzip
          ls -lah data/

      - name: Check downloaded files
        run: ls -lah data/

      - name: Upload dataset to Spark
        run: |
          SPARK_DIR="/opt/spark"
          spark-submit --class org.apache.spark.examples.SparkPi --master local[*] $SPARK_DIR/examples/jars/spark-examples_2.12-${{ matrix.spark }}.jar 1000

      - name: Run Spark operations
        run: |
          # Пример операции с PySpark
          echo "from pyspark.sql import SparkSession" > /tmp/spark_query.py
          echo "spark = SparkSession.builder.appName('Netflix').getOrCreate()" >> /tmp/spark_query.py
          echo "df = spark.read.csv('/data/netflix_titles.csv', header=True, inferSchema=True)" >> /tmp/spark_query.py
          echo "df.show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Save Spark results to JSON
        run: |
          OUTPUT_FILE="/tmp/spark_output.json"
          echo "{" > $OUTPUT_FILE

          echo '"top_titles":' >> $OUTPUT_FILE
          spark-submit /tmp/spark_query.py | jq -R -s -c 'split("\n")[:-1]' >> $OUTPUT_FILE
          echo "," >> $OUTPUT_FILE

          echo '"average_duration":' >> $OUTPUT_FILE
          spark-submit /tmp/spark_query.py | jq -R -s -c 'split("\n")[:-1]' >> $OUTPUT_FILE
          echo "," >> $OUTPUT_FILE

          echo '"release_year_count":' >> $OUTPUT_FILE
          spark-submit /tmp/spark_query.py | jq -R -s -c 'split("\n")[:-1]' >> $OUTPUT_FILE
          echo "," >> $OUTPUT_FILE

          echo "}" >> $OUTPUT_FILE

      - name: Upload Spark results as JSON
        uses: actions/upload-artifact@v4
        with:
          name: spark-output
          path: /tmp/spark_output.json

    
