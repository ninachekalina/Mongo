name: Spark CI

on:
  push:
    branches:
      - main
    paths:
      - '.github/workflows/spark.yml'
  pull_request:
    branches:
      - main
    paths:
      - '.github/workflows/spark.yml'
  workflow_dispatch:
    inputs:
      query_key:
        description: 'Key to extract query from artifact'
        required: false

jobs:
  spark-submit:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'

      - name: Setup Spark
        uses: vemonet/setup-spark@v1
        with:
          spark-version: '3.5.3'
          hadoop-version: '3'

      - name: Check Spark version
        run: spark-submit --version

      - name: Install Kaggle CLI
        run: |
          pip install kaggle

      - name: Download Netflix dataset from Kaggle
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        run: |
          mkdir -p data
          kaggle datasets download -d chekalinanina/netflix-titles -p data --unzip
          ls -lah data/

      - name: Check downloaded files
        run: ls -lah data/

      - name: Run query for unique genres
        run: |
          echo "from pyspark.sql import SparkSession" > /tmp/spark_query.py
          echo "spark = SparkSession.builder.appName('Netflix').getOrCreate()" >> /tmp/spark_query.py
          echo "df = spark.read.csv('/home/runner/work/Mongo/Mongo/data/netflix_titles.csv', header=True, inferSchema=True)" >> /tmp/spark_query.py
          echo "df.select('listed_in').distinct().show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movies after 2015
        run: |
          echo "df.filter(df['release_year'] > 2015).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for top 10 longest movies
        run: |
          echo "df.orderBy(df['duration'], ascending=False).limit(10).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movie count by type
        run: |
          echo "df.groupBy('type').count().show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movie count by release year
        run: |
          echo "df.groupBy('release_year').count().show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for top 5 longest movies
        run: |
          echo "df.orderBy(df['duration'], ascending=False).limit(5).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movies with rating "TV-MA"
        run: |
          echo "df.filter(df['rating'] == 'TV-MA').show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movies with rating "PG-13"
        run: |
          echo "df.filter(df['rating'].isin('PG', 'PG-13')).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movies with unknown actors
        run: |
          echo "df.filter(df['cast'].isNull()).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run Spark operation to find top 10 longest titles
        run: |
          echo "from pyspark.sql.functions import length" >> /tmp/spark_query.py
          echo "df.orderBy(length(df['title']).desc()).limit(10).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py


      - name: Run query for average movie duration by genre
        run: |
          echo "df.groupBy('listed_in').agg({'duration': 'avg'}).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for most frequent movie genres
        run: |
          echo "df.groupBy('listed_in').count().orderBy('count', ascending=False).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movies with description
        run: |
          echo "df.filter(df['description'].isNotNull()).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for average duration by country
        run: |
          echo "df.groupBy('country').agg({'duration': 'avg'}).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movies released in 2020
        run: |
          echo "df.filter(df['release_year'] == 2020).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movies released in the last 5 years
        run: |
          echo "df.filter(df['release_year'] > 2017).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for top rated movies
        run: |
          echo "df.filter(df['rating'] == 'PG').orderBy(df['duration'], ascending=False).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movies longer than 90 minutes
        run: |
          echo "df.filter(df['duration'] > 90).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for most common release years
        run: |
          echo "df.groupBy('release_year').count().orderBy('count', ascending=False).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movies with multiple genres
        run: |
          echo "df.filter(df['listed_in'].contains(',')).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Run query for movies with a specific keyword in the description
        run: |
          echo "df.filter(df['description'].contains('love')).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      - name: Upload Spark results as JSON
        uses: actions/upload-artifact@v4
        with:
          name: spark-output
          path: /tmp/spark_output.json

