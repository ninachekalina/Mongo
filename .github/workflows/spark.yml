name: Spark CI

on:
  push:
    branches:
      - main
    paths:
      - '.github/workflows/spark.yml'
  pull_request:
    branches:
      - main
    paths:
      - '.github/workflows/spark.yml'
  workflow_dispatch:
    inputs:
      query_key:
        description: 'Key to extract query from artifact'
        required: false

jobs:
  spark-submit:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'

      - name: Setup Spark
        uses: vemonet/setup-spark@v1
        with:
          spark-version: '3.5.3'
          hadoop-version: '3'

      - name: Check Spark version
        run: spark-submit --version

      - name: Install Kaggle CLI
        run: |
          pip install kaggle
          
      - name: Download Netflix dataset from Kaggle
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        run: |
          mkdir -p data
          kaggle datasets download -d chekalinanina/netflix-titles -p data --unzip
          ls -lah data/

      - name: Check downloaded files
        run: ls -lah data/

      # Query 1: Unique genres
      - name: Run query for unique genres
        run: |
          echo "from pyspark.sql import SparkSession" > /tmp/spark_query.py
          echo "spark = SparkSession.builder.appName('Netflix').getOrCreate()" >> /tmp/spark_query.py
          echo "df = spark.read.csv('data/netflix_titles.csv', header=True, inferSchema=True)" >> /tmp/spark_query.py
          echo "result = df.select('listed_in').distinct().collect()" >> /tmp/spark_query.py
          echo "import json" >> /tmp/spark_query.py
          echo "with open('/tmp/spark_output.json', 'w') as f:" >> /tmp/spark_query.py
          echo "    json.dump({'unique_genres': [row['listed_in'] for row in result]}, f)" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 2: Movies after 2015
      - name: Run query for movies after 2015
        run: |
          echo "df.filter(df['release_year'] > 2015).show()" >> /tmp/spark_query.py
          echo "import json" >> /tmp/spark_query.py
          echo "with open('/tmp/spark_output.json', 'w') as f:" >> /tmp/spark_query.py
          echo "    json.dump({'movies_after_2015': [row['title'] for row in result]}, f)" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 3: Top 10 longest movies
      - name: Run query for top 10 longest movies
        run: |
          echo "df.orderBy(df['duration'], ascending=False).limit(10).show()" >> /tmp/spark_query.py
          echo "import json" >> /tmp/spark_query.py
          echo "with open('/tmp/spark_output.json', 'w') as f:" >> /tmp/spark_query.py
          echo "    json.dump({'top_10_longest_movies': [row['title'] for row in result]}, f)" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 4: Movie count by type
      - name: Run query for movie count by type
        run: |
          echo "df.groupBy('type').count().show()" >> /tmp/spark_query.py
          echo "import json" >> /tmp/spark_query.py
          echo "with open('/tmp/spark_output.json', 'w') as f:" >> /tmp/spark_query.py
          echo "    json.dump({'movie_count_by_type': [row['type'] for row in result]}, f)" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 5: Movie count by release year
      - name: Run query for movie count by release year
        run: |
          echo "df.groupBy('release_year').count().show()" >> /tmp/spark_query.py
          echo "import json" >> /tmp/spark_query.py
          echo "with open('/tmp/spark_output.json', 'w') as f:" >> /tmp/spark_query.py
          echo "    json.dump({'movie_count_by_year': [row['release_year'] for row in result]}, f)" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 6: Top 5 longest movies
      - name: Run query for top 5 longest movies
        run: |
          echo "df.orderBy(df['duration'], ascending=False).limit(5).show()" >> /tmp/spark_query.py
          echo "import json" >> /tmp/spark_query.py
          echo "with open('/tmp/spark_output.json', 'w') as f:" >> /tmp/spark_query.py
          echo "    json.dump({'top_5_longest_movies': [row['title'] for row in result]}, f)" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 7: Movies with rating "TV-MA"
      - name: Run query for movies with rating "TV-MA"
        run: |
          echo "df.filter(df['rating'] == 'TV-MA').show()" >> /tmp/spark_query.py
          echo "import json" >> /tmp/spark_query.py
          echo "with open('/tmp/spark_output.json', 'w') as f:" >> /tmp/spark_query.py
          echo "    json.dump({'tv_ma_movies': [row['title'] for row in result]}, f)" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 8: Movies with rating "PG" or "PG-13"
      - name: Run query for movies with rating "PG" or "PG-13"
        run: |
          echo "df.filter(df['rating'].isin('PG', 'PG-13')).show()" >> /tmp/spark_query.py
          echo "import json" >> /tmp/spark_query.py
          echo "with open('/tmp/spark_output.json', 'w') as f:" >> /tmp/spark_query.py
          echo "    json.dump({'pg_pg13_movies': [row['title'] for row in result]}, f)" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 9: Movies with unknown actors
      - name: Run query for movies with unknown actors
        run: |
          echo "df.filter(df['cast'].isNull()).show()" >> /tmp/spark_query.py
          echo "import json" >> /tmp/spark_query.py
          echo "with open('/tmp/spark_output.json', 'w') as f:" >> /tmp/spark_query.py
          echo "    json.dump({'movies_with_unknown_actors': [row['title'] for row in result]}, f)" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 10: Top 10 longest titles
      - name: Run Spark operation to find top 10 longest titles
        run: |
          echo "from pyspark.sql.functions import length" >> /tmp/spark_query.py
          echo "df.orderBy(length(df['title']).desc()).limit(10).show()" >> /tmp/spark_query.py
          echo "import json" >> /tmp/spark_query.py
          echo "with open('/tmp/spark_output.json', 'w') as f:" >> /tmp/spark_query.py
          echo "    json.dump({'top_10_longest_titles': [row['title'] for row in result]}, f)" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 11: Average movie duration by genre
      - name: Run query for average movie duration by genre
        run: |
          echo "df.groupBy('listed_in').agg({'duration': 'avg'}).show()" >> /tmp/spark_query.py
          echo "import json" >> /tmp/spark_query.py
          echo "with open('/tmp/spark_output.json', 'w') as f:" >> /tmp/spark_query.py
          echo "    json.dump({'avg_duration_by_genre': [row['listed_in'] for row in result]}, f)" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 12: Most frequent movie genres
      - name: Run query for most frequent movie genres
        run: |
          echo "df.groupBy('listed_in').count().orderBy('count', ascending=False).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 13: Movies with description
      - name: Run query for movies with description
        run: |
          echo "df.filter(df['description'].isNotNull()).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 14: Average duration by country
      - name: Run query for average duration by country
        run: |
          echo "df.groupBy('country').agg({'duration': 'avg'}).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 15: Movies released in 2020
      - name: Run query for movies released in 2020
        run: |
          echo "df.filter(df['release_year'] == 2020).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 16: Movies released in the last 5 years
      - name: Run query for movies released in the last 5 years
        run: |
          echo "df.filter(df['release_year'] > 2017).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 17: Top rated movies
      - name: Run query for top rated movies
        run: |
          echo "df.filter(df['rating'] == 'PG').orderBy(df['duration'], ascending=False).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 18: Movies longer than 90 minutes
      - name: Run query for movies longer than 90 minutes
        run: |
          echo "df.filter(df['duration'] > 90).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 19: Most common release years
      - name: Run query for most common release years
        run: |
          echo "df.groupBy('release_year').count().orderBy('count', ascending=False).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Query 20: Movies with multiple genres
      - name: Run query for movies with multiple genres
        run: |
          echo "df.filter(df['listed_in'].contains(',')).show()" >> /tmp/spark_query.py
          spark-submit /tmp/spark_query.py

      # Upload the results as an artifact
      - name: Upload Spark results as JSON
        uses: actions/upload-artifact@v4
        with:
          name: spark-output
          path: /tmp/spark_output.json
