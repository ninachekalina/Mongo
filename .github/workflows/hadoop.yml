name: Hadoop CI

on:
  push:
    branches:
      - main
    paths:
      - '.github/workflows/hadoop.yml'
      - 'test_queries_hadoop.sql'
  pull_request:
    branches:
      - main
    paths:
      - '.github/workflows/hadoop.yml'
      - 'test_queries_hadoop.sql'
  workflow_dispatch:

jobs:
  test-hadoop:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y openjdk-17-jdk ssh
      
      - name: Download and extract Hadoop
        run: |
          wget -nc -q https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
          tar -xzf hadoop-3.3.6.tar.gz -C /opt/
          mv /opt/hadoop-3.3.6 /opt/hadoop
          echo "HADOOP_HOME=/opt/hadoop" >> $GITHUB_ENV
          echo "PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH" >> $GITHUB_ENV
      
      - name: Configure SSH for Hadoop
        run: |
          ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa
          cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
          chmod 600 ~/.ssh/authorized_keys
          echo "StrictHostKeyChecking no" >> ~/.ssh/config
          echo "UserKnownHostsFile=/dev/null" >> ~/.ssh/config
      
      - name: Configure Hadoop
        run: |
          cat <<EOF > /opt/hadoop/etc/hadoop/core-site.xml
          <configuration>
            <property>
              <name>fs.defaultFS</name>
              <value>hdfs://localhost:9000</value>
            </property>
          </configuration>
          EOF
          cat <<EOF > /opt/hadoop/etc/hadoop/hdfs-site.xml
          <configuration>
            <property>
              <name>dfs.replication</name>
              <value>1</value>
            </property>
          </configuration>
          EOF
      
      - name: Format NameNode
        run: /opt/hadoop/bin/hdfs namenode -format

      - name: Start Hadoop
        run: |
          /opt/hadoop/sbin/start-dfs.sh
          sleep 5
          jps  # Проверка запущенных процессов
      
      - name: Create user directory in HDFS
        run: /opt/hadoop/bin/hdfs dfs -mkdir -p /user/runner

      - name: Check HDFS before put
        run: /opt/hadoop/bin/hdfs dfs -ls /user/runner

      - name: Test HDFS connectivity
        run: /opt/hadoop/bin/hdfs dfsadmin -report

      - name: Verify test SQL file
        run: |
          ls -l
          cat test_queries_hadoop.sql || echo "Файл test_queries_hadoop.sql не найден!"
      
      - name: Create /tmp/ directory in HDFS
        run: |
          /opt/hadoop/bin/hdfs dfs -mkdir -p /tmp/
          /opt/hadoop/bin/hdfs dfs -chmod 777 /tmp/

      - name: Try alternative put
        run: /opt/hadoop/bin/hdfs dfs -put test_queries_hadoop.sql /tmp/

      - name: Run Hadoop test queries
        run: /opt/hadoop/bin/hdfs dfs -put test_queries_hadoop.sql /user/runner/

      
      - name: Upload Hadoop results
        uses: actions/upload-artifact@v4
        with:
          name: hadoop-output
          path: test_queries_hadoop.sql

